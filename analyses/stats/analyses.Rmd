---
output:
    html_document:
        theme: journal
        highlight: zenburn
---

```{r setup}
library(dplyr)
library(here)
library(cmdstanr)
library(purrr)
library(ggplot2)
library(duckdb)
library(readr)
library(knitr)
library(kableExtra)

ggplot2::theme_set(ggplot2::theme_minimal())

m_data <- readRDS(
  here::here(
    "analyses",
    "stats",
    "analyses_model_fit.RData"
  )
)

d_observed <- readr::read_delim(
  file = here::here(
    "data",
    "analysis",
    "analysis-data.delim"
  ),
  delim = "|"
)

duck_conn <- DBI::dbConnect(
  drv = duckdb::duckdb(),
  dbdir = here::here(
    "data",
    "analysis",
    "analyses_model_generated-quantities.duckdb"
  ),
  read_only = TRUE
)

DBI::dbExecute(
  conn = duck_conn,
  statement = "SET enable_progress_bar=true"
)
DBI::dbExecute(
  conn = duck_conn,
  statement = "SET threads TO 4"
)
```

# Checking the sampling behavior

```{r extract_draws_and_summary, cache = TRUE}
d_posterior_draws <- m_data$draws(format = "df")

d_posterior_summary <- m_data$summary()
.quantiles <- m_data$summary(
  quantiles = ~ quantile(., probs = c(0.025, 0.975))
) %>%
  dplyr::rename(
    .,
    "q025" = "2.5%",
    "q975" = "97.5%"
  )
d_posterior_summary <- d_posterior_summary %>%
  dplyr::left_join(
    .,
    .quantiles,
    by = "variable"
  ) %>%
  dplyr::select(
    .,
    -c(q5, q95)
  )
```

Check the range of effective sample sizes:

```{r check_ess}
d_posterior_summary %>%
  dplyr::select(
    .,
    ess_bulk,
    ess_tail
  ) %>%
  purrr::map(., range)
```

ESSs just above 10k seem a little low. Examine the distribution:

```{r ess_distributions}
d_posterior_summary %>%
  ggplot2::ggplot(
    data = .,
    mapping = ggplot2::aes(
      x = ess_bulk
    )
  ) +
  ggplot2::geom_histogram(
    binwidth = 200
  )
```

Most of the parameters have ESSs well above 75k, which is great. Let's see
which parameters have ESSs less than 25k:

```{r ess_le_25k}
d_posterior_summary %>%
  dplyr::filter(
    .,
    ess_bulk < 25000
  ) %>%
  dplyr::select(
    ,
    variable,
    ess_bulk
  ) %>%
  dplyr::arrange(
    .,
    dplyr::desc(ess_bulk)
  ) %>%
  print.data.frame()
```

Most of the parameters are participant-specific deflections from the grand
mean.

# Model inference

We fit a hierarchical Bayesian model using the Stan probabilistic programming
language (REFERENCA) and the `cmdstanr` interface (REFERENCA) for the R
programming language (REFERENCA). The model we fit assumes that each reaction
time \(RT_{i}\) (where \(i \in \{1, \ldots, N\}\) indexes observations to which
we fit the model) comes from a shifted log-normal distribution:

\[
    RT_{i} \sim \textrm{ShiftLogNormal}(\mu_{i}, \sigma, \delta_{P(i)}).
\]

We assumed that each distribution's mean \(\mu_{i}\) depends on the features
of the pertinent word (\(W_{i}\)), as well as participant-specific
(\(\alpha_{P(i)}\)) and word-specific (\(\gamma_{W(i)}\)) factors. As mentioned
earlier, the word features we examined are word length
(\(L_{i}\)), its subjective frequency (\(F_{i}\)), it age-of-acquisition
(\(A_{i}\)), and its concreteness (\(C_{i}\)), with each feature's contribution
presented by a \(\beta\) parameter. All these factors were represented as
deflections from the grand mean \(\alpha_{0}\):

\[
    \mu_i = \alpha_{0} +
        \alpha_{P(i)} +
        L_i \times \beta_L +
        F_i \times \beta_F +
        A_i \times \beta_A +
        C_i \times \beta_C +
        \gamma_{W(i)}.
\]

We assumed a fixed variance of each of the reaction times' distributions
(\(\sigma\)). Finally, to move the values sampled from the log-normal
distributions away from zero (as reaction times cannot realistically be around
zero milliseconds), we assumed a participant-specific shift parameter
\(\delta_{P(i)}\).

The model priors were set so as to try to constrain the values of the
parameters to a range which is plausible given existing research. The complete
procedure for generating the priors is visible in the supplementary materials.

# Model fit

```{r gen_quant_data}
. <- DBI::dbGetQuery(
  conn = duck_conn,
  statement = "
    SELECT max(draw) AS max_draw
    FROM generated_quantities
  "
) %>%
  dplyr::pull(max_draw)

l_gen_quant <- list(
  "n_draws" = .
)
```

In order to asses model fit, we simulated `r l_gen_quant[['n_draws']]` sets of
reaction times from the fitted model, using the obtained posterior parameter
estimates. \ref{fig_ppc_raw_data} shows a random sample of 1000 of the
individual observed reaction times (ordered by magnitude). The shaded area
marks the range which contains the central 90% of the simulated reaction time
value distributions for each data point.

We see that the reaction time values simulated from the fitted model are mostly
compatible with the observed values. The most severe fit issues are visible for
observed values having reaction times above approximately 1 second. This may
not be surprising since such reaction times make up only
`r round(mean(d_observed$stimulus_rt >= 1000) * 100, 2)`% of the complete
dataset, and represent reactions which may be considered outliers (the
longest observed reaction time in the plotted sample was longer than 5
seconds, and its point is not visible in \ref{fig_ppc_raw_data}).

```{r fig.cap="\\label{fig_ppc_raw_data}", dev="png", cache=TRUE}
set.seed(1)
sample_idx <- sample(
  x = 1:nrow(d_observed),
  size = 1000,
  replace = FALSE
) %>%
  sort()


d_observed$rt_id <- 1:nrow(d_observed)
d_observed_sample <- dplyr::filter(
  .data = d_observed,
  rt_id %in% sample_idx
)
d_observed_sample <- dplyr::arrange(
  .data = d_observed_sample,
  stimulus_rt
)

d_rep_summarised <- DBI::dbGetQuery(
  conn = duck_conn,
  statement = "
    SELECT y_rt_rep_id,
        quantile(y_rt_rep_ms, 0.9) AS q90_rt_ms,
        quantile(y_rt_rep_ms, 0.1) AS q10_rt_ms
    FROM generated_quantities
    WHERE y_rt_rep_id IN ( ? )
    GROUP BY y_rt_rep_id
    ORDER BY y_rt_rep_id
  ",
  list(sample_idx)
)
d_rep_summarised <- d_rep_summarised[
  base::match(d_observed_sample$rt_id, d_rep_summarised$y_rt_rep_id),
]

d_rep_summarised$plotting_id <- 1:nrow(d_rep_summarised)
d_observed_sample$plotting_id <- 1:nrow(d_observed_sample)

d_rep_summarised %>%
  ggplot2::ggplot(
    data = .,
    mapping = ggplot2::aes(
      x = plotting_id,
      ymin = q10_rt_ms,
      ymax = q90_rt_ms
    )
  ) +
  ggplot2::geom_ribbon(color = "grey", fill = "grey") +
  ggplot2::geom_point(
    inherit.aes = FALSE,
    data = d_observed_sample,
    mapping = aes(
      x = plotting_id,
      y = stimulus_rt
    ),
    shape = 20
  ) +
  ggplot2::coord_cartesian(
    ylim = c(0, 3000)
  ) +
  ggplot2::scale_y_continuous(
    breaks = seq(0, 3000, 500)
  ) +
  ggplot2::theme(
    panel.grid.major.y = ggplot2::element_line(
      linetype = "dashed",
      color = "black",
      linewidth = 0.1
    )
  ) +
  ggplot2::labs(
    x = "Reaction time ID",
    y = "Reaction time (ms)"
  )
```

# Parameter estimates

The parameters we were most interested in were the coefficients for the
association between reaction times and word length, age of acquisition,
concreteness and subjective frequency. The posterior parameter estimates
obtained after fitting the model are shown in the table below:

```{r parameter estimates}
d_posterior_summary %>%
  dplyr::filter(
    .,
    startsWith(variable, "beta")
  ) %>%
  dplyr::select(
    .,
    variable,
    mean,
    median,
    sd,
    q025,
    q975
  ) %>%
  dplyr::mutate(
    .,
    dplyr::across(
      .cols = variable,
      .fn = \(varname) dplyr::case_when(
        varname == "beta_length" ~ "Length",
        varname == "beta_aoa" ~ "AoA",
        varname == "beta_subfreq" ~ "Subjective frequency",
        varname == "beta_concreteness" ~ "Concreteness"
      )
    )
  ) %>%
  knitr::kable(
    .,
    format = "html",
    col.names = c(
      "Variable",
      "Mean",
      "Median",
      "SD",
      "Q00.25",
      "Q97.50"
    ),
    digits = 3,
    caption = "
        A summary of 40000 posterior estimates of the coefficients
        for word length, concreteness, subjective frequency and age
        of acquisition (AoA).
    "
  ) %>%
  kableExtra::kable_styling()
```

As can be seen by looking at the central 95% percentile intervals in the table
above, all coefficients except for the one associated with word concreteness
do not entail zero. They also imply relations consistent with extant literature
--- longer reaction times are associated with longer words and words that were
acquired later in life. On the other hand, shorter reaction times are associated
with words which are encountered more often in everyday life.

Since we have assumed that the reaction times can be modeled by a shifted
lognormal distribution, the interpretaion of the estimated coefficients may
be unintuitive. This is because a unit increase in one of the predictors
is not related to a constant increase in the criterion. Therefore, we produce
the plots below, which show the predicted reaction times when all predictors
except a focal one are fixed to a certain value.

We'll fix each of the non-focal predictors' value to the sample mean. The
participant-specific \(alpha_S\) coefficients are set to 0, which corresponds
to no strong participant-specific contribution to the magnitude of the predicted
reaction times. The same was done for the word-specific coefficients
\(\gamma_W\). The \(delta\) coefficient was also set to 0 since it only shifts
the distribution left or right, and doesn't influence the relationship between
the other predictors. Furthermore, the \(\alpha_0\) and \(\delta\)
coefficients are set to their respective posterior means.

```{r closing}
DBI::dbDisconnect(con = duck_conn, shutdown = TRUE)
```

